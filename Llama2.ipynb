{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2KGPRxxJKfmn"
   },
   "source": [
    "# **How to use Llama 2**\n",
    "## _An open source large language model_\n",
    "\n",
    "By Chanin Nantasenamat\n",
    "\n",
    "_Data Professor_ YouTube channel, https://youtube.com/dataprofessor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FIf3Q7QaK4gn"
   },
   "source": [
    "## **Install replicate**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "cGwfwAsLJsSR"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting replicate\n",
      "  Downloading https://files.pythonhosted.org/packages/5b/73/f94cbd9f8aeab60abf949d816d5da33504fd583e2d53468e708311e8035e/replicate-0.10.0-py3-none-any.whl\n",
      "Collecting pydantic>1\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/87/80/52770e747e4bee5012e60b2684db36c8fdf010f8dadb4ded0efec808b07d/pydantic-2.1.1-py3-none-any.whl (370kB)\n",
      "\u001b[K     |████████████████████████████████| 378kB 14.8MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting packaging\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ab/c3/57f0601a2d4fe15de7a553c00adbc901425661bf048f2a22dfc500caf121/packaging-23.1-py3-none-any.whl (48kB)\n",
      "\u001b[K     |████████████████████████████████| 51kB 33.5MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting requests>2\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/70/8e/0e2d847013cb52cd35b38c009bb167a1a26b2ce6cd6965bf26b47bc0bf44/requests-2.31.0-py3-none-any.whl (62kB)\n",
      "\u001b[K     |████████████████████████████████| 71kB 39.5MB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting annotated-types>=0.4.0\n",
      "  Downloading https://files.pythonhosted.org/packages/d8/f0/a2ee543a96cc624c35a9086f39b1ed2aa403c6d355dfe47a11ee5c64a164/annotated_types-0.5.0-py3-none-any.whl\n",
      "Collecting pydantic-core==2.4.0\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/02/bf/a193e0f4a0fa01b8d6791991ecf1500931f8c98ccf81307ade3ad10963d7/pydantic_core-2.4.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.9MB)\n",
      "\u001b[K     |████████████████████████████████| 1.9MB 85.8MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting typing-extensions>=4.6.1\n",
      "  Downloading https://files.pythonhosted.org/packages/ec/6b/63cc3df74987c36fe26157ee12e09e8f9db4de771e0f3404263117e75b95/typing_extensions-4.7.1-py3-none-any.whl\n",
      "Collecting idna<4,>=2.5\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fc/34/3030de6f1370931b9dbb4dad48f6ab1015ab1d32447850b9fc94e60097be/idna-3.4-py3-none-any.whl (61kB)\n",
      "\u001b[K     |████████████████████████████████| 71kB 43.6MB/s  eta 0:00:01\n",
      "\u001b[?25hCollecting urllib3<3,>=1.21.1\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9b/81/62fd61001fa4b9d0df6e31d47ff49cfa9de4af03adecf339c7bc30656b37/urllib3-2.0.4-py3-none-any.whl (123kB)\n",
      "\u001b[K     |████████████████████████████████| 133kB 113.7MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting charset-normalizer<4,>=2\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/f9/0d/514be8597d7a96243e5467a37d337b9399cec117a513fcf9328405d911c0/charset_normalizer-3.2.0-cp39-cp39-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (202kB)\n",
      "\u001b[K     |████████████████████████████████| 204kB 118.8MB/s eta 0:00:01\n",
      "\u001b[?25hCollecting certifi>=2017.4.17\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/4c/dd/2234eab22353ffc7d94e8d13177aaa050113286e93e7b40eae01fbf7c3d9/certifi-2023.7.22-py3-none-any.whl (158kB)\n",
      "\u001b[K     |████████████████████████████████| 163kB 115.0MB/s eta 0:00:01\n",
      "\u001b[31mERROR: jupyterlab 3.2.4 has requirement jupyter-server~=1.4, but you'll have jupyter-server 2.0.0a1 which is incompatible.\u001b[0m\n",
      "\u001b[31mERROR: jupyterlab-server 2.22.1 has requirement jsonschema>=4.17.3, but you'll have jsonschema 3.2.0 which is incompatible.\u001b[0m\n",
      "\u001b[?25hInstalling collected packages: annotated-types, typing-extensions, pydantic-core, pydantic, packaging, idna, urllib3, charset-normalizer, certifi, requests, replicate\n",
      "Successfully installed annotated-types-0.5.0 certifi-2023.7.22 charset-normalizer-3.2.0 idna-3.4 packaging-23.1 pydantic-2.1.1 pydantic-core-2.4.0 replicate-0.10.0 requests-2.31.0 typing-extensions-4.7.1 urllib3-2.0.4\n",
      "\u001b[33mWARNING: You are using pip version 19.3.1; however, version 23.2.1 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! pip install replicate"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HqBzUTg9NMdh"
   },
   "source": [
    "## **Set Replicate API token**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "_ga2m-1FNP7o"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "os.environ[\"REPLICATE_API_TOKEN\"] = \"r8_AzNrdqkYdFItp0j5hOIwAzIjghwPTjn48T2Pr\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "901Hxea9K7ME"
   },
   "source": [
    "## **Run the Llama 2 model**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "7Eyzd9DQRvh6"
   },
   "outputs": [],
   "source": [
    "import replicate\n",
    "\n",
    "# Prompts\n",
    "pre_prompt = \"You are a helpful assistant. You do not respond as 'User' or pretend to be 'User'. You only respond once as 'Assistant'.\"\n",
    "prompt_input = \"Who is chief prime minister of India?\"\n",
    "\n",
    "# Generate LLM response\n",
    "output = replicate.run('a16z-infra/llama13b-v2-chat:df7690f1994d94e96ad9d568eac121aecf50684a0b0963b25a41cc40061269e5', # LLM model\n",
    "                        input={\"prompt\": f\"{pre_prompt} {prompt_input} Assistant: \", # Prompts\n",
    "                        \"temperature\":0.1, \"top_p\":0.9, \"max_length\":128, \"repetition_penalty\":1})  # Model parameters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YrSrbZ97OU3W"
   },
   "source": [
    "## **Displaying the LLM generated response**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ZDH_FJJCKHRo",
    "outputId": "cbf47b42-9225-4368-8f91-a64606575b38"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<generator object Prediction.output_iterator at 0x7fc45b1e4660>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rwNZxpzFNnnM",
    "outputId": "959f878b-757a-4341-ee4b-30318be5871b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The current Prime Minister of India is Narendra Modi.\n"
     ]
    }
   ],
   "source": [
    "full_response = \"\"\n",
    "\n",
    "for item in output:\n",
    "  full_response += item\n",
    "\n",
    "print(full_response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
